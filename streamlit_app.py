import streamlit as st
from openai import OpenAI
import pandas as pd
import os
from supabase import create_client
from datetime import datetime
import json
import copy
# CSVì—ì„œ ë°ì´í„° ë¡œë“œ

first_prompt = """
ë„ˆëŠ” ìœ ì €ì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ëŠ” AIì•¼! ìœ ì €ì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ì–´ì§„ ì¡°ê±´ì— ë§ë„ë¡ ì§ˆë¬¸ì„ ë¶„ì„í•´ì¤˜!

ì¡°ê±´ 1. ì•„ë˜ Task ë¦¬ìŠ¤íŠ¸ ì¤‘ 1ê°œì˜ ì‘ì—… ì„ íƒ!
Task : ["ReAsk", "FindProduct", "Recommandation", "Etc"]
ì¡°ê±´ 2. ë§Œì•½, Taskê°€ "FindProduct"ë¼ë©´, ì›í•˜ëŠ” "Product"ë¥¼ "Option"ìœ¼ë¡œ ì •ì˜ë¥¼ í•´ì¤˜!
ì¡°ê±´ 3. ë§Œì•½, Taskê°€ "Recommandation"ë¼ë©´, ìœ ì €ì˜ ì¡°ê±´ì„ "Condition"ì´ë¼ê³  "Option"ì— ì œê³µí•´ì¤˜!
ì¡°ê±´ 4. ë§Œì•½, Taskê°€ "ReAsk"ë¼ë©´, ìœ ì €ì˜ ì§ˆë¬¸ì—ì„œ ì¶”ê°€ì ìœ¼ë¡œ ìš”êµ¬ë˜ëŠ” ì¡°ê±´ì„ "Condition"ì´ë¼ê³  "Option"ì— ì œê³µí•´ì¤˜!
** ì¡°ê±´ 5. í™”ì¥í’ˆ ê´€ë ¨ ì´ì•¼ê¸°ë¥¼ ì œì™¸í•œ ë‹¤ë¥¸ ì´ì•¼ê¸°ëŠ” ë‹µí•  ìˆ˜ ì—†ë‹¤ëŠ” ë‚´ìš©ìœ¼ë¡œ ë‹µë³€ì„ í•´ì¤˜! **

OUTPUT í¬ë§·
```json
{
    "Task":"...",
    "Option":{"...":"...",  ..., key:val}
}
```
"""


# Supabase ì„¤ì •
supabase_url = os.getenv("SUPABASE_URL")
supabase_key = os.getenv("SUPABASE_KEY")
supabase = create_client(supabase_url, supabase_key)

# Supabase ë¡œê¹… í•¨ìˆ˜
def log_to_supabase(question, answer, history):
    try:
        timestamp = datetime.now().isoformat()
        supabase.table("chat_log").insert({
            "question": question,
            "answer": answer,
            "history": json.dumps(history, ensure_ascii=False),
            "timestamp": timestamp
        }).execute()
    except:
        pass
def local_RAG(model, messages, client, vector_id):
    response = client.responses.create(
        model=model,
        input=messages[-1]['content'],
        tools=[{
                "type": "file_search",
                "vector_store_ids": [vector_id],
                "max_num_results": 5
        }]
        )
    if response.output[0].results == None:
        return ""
    return response.output[1].content[0].text

def generate(model, messages, client):
    response = client.chat.completions.create(
        model=model,
        messages=messages,
    )
    return response.choices[0].message.content

def routing(prompt, user_input, client):
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": user_input}
    ]

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        response_format={"type": "json_object"}
    )
    query_parsing = json.loads(response.choices[0].message.content)
    return query_parsing

def generate_response(query_parsing, client, vector_id, messages):
    response = ""
    if "Task" not in query_parsing.keys():
        response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì›í•˜ì‹œëŠ” ë‚´ìš©ì„ ì œëŒ€ë¡œ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."

    if query_parsing["Task"] == "ReAsk":
        response = "ê´€ì‹¬ ìˆëŠ” ì œí’ˆì— ëŒ€í•´ì„œ ìì„¸íˆ(ex. ì´ë¦„, ë¸Œëœë“œ, ë©”ì´ì»¤) ì•Œë ¤ì£¼ì„¸ìš”. ë˜ëŠ” ì›í•˜ì‹œëŠ” ì¡°ê±´ì— ëŒ€í•´ì„œ ìì„¸íˆ(ex. ê±´ì„± í”¼ë¶€ìš©) ì•Œë ¤ì£¼ì„¸ìš”"


    if query_parsing["Task"] == "FindProduct":
        if "Option" not in query_parsing.keys():
            response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì›í•˜ì‹œëŠ” ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì°¾ìœ¼ì‹œëŠ” ì œí’ˆì— ëŒ€í•´ì„œì„œ ëª…í™•í•˜ê²Œ ë‹¤ì‹œ ì•Œë ¤ì£¼ì„¸ìš”"

        product = query_parsing['Option']["Product"]
        product_list = supabase.table("cosmetics").select("*").execute().data

        find_data = ""
        for item in product_list:
            if product in item["title"]:
                find_data += f"item : {item['title']}\tbrand : {item['brand']}\tmake : {item['maker']}\tsummary : {item['summary']}\n\n"

        messages[0]['content'] = response_prompt

        if len(find_data)>2:
            messages[-1]['content'] = messages[-1]['content'] +"\n\n<ë°ì´í„°>\n\n" + find_data +"\n\n</ë°ì´í„°>\n\n" + messages[-1]['content']
            response = generate("gpt-4o", messages, client)

        else:
            if "brand" in query_parsing['Option'].keys() or "maker" in query_parsing['Option'].keys():
                response = local_RAG("gpt-4o", messages, client, vector_id)
                if response == "":
                    response = generate("gpt-4o-search-preview", messages, client)
            else:
                response = generate("gpt-4o-search-preview", messages, client)

    if query_parsing["Task"] == "Recommandation":
        response = local_RAG("gpt-4o", messages, client, vector_id)
        if response == "":
            response = generate("gpt-4o-search-preview", messages, client)

    return response
# CSV ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë§ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜


# Show title and description.
st.title("ğŸ’¬ Chatbot")

# Select language
language = st.selectbox("Choose your language:", ["English", "í•œêµ­ì–´", "EspaÃ±ol", "ä¸­æ–‡", "æ—¥æœ¬èª", "à¸ à¸²à¸©à¸²à¹„à¸—à¸¢", "Tiáº¿ng Viá»‡t", "Bahasa Indonesia"])

response_prompt = f"""
ë„ˆëŠ” í™”ì¥í’ˆì„ ìƒë‹´í•´ ì£¼ëŠ” AIì•¼!
ìœ ì €ì˜ í™”ì¥í’ˆ ê´€ë ¨ëœ ì§ˆë¬¸ì— ê°€ì¥ ì ì ˆí•œ ë‹µë³€ì„ í•´ì¤˜!

ì¡°ê±´1 : í™”ì¥í’ˆê³¼ ê´€ë ¨ë˜ì§€ ì•Šì€ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ëŒ€ë‹µì„ í•˜ì§€ ì•Šë„ë¡ í•´ì¤˜
ì¡°ê±´2 : ì£¼ì–´ì§„ languageì— ë§ëŠ” ì–¸ì–´ë¡œ ë‹µë³€ì„ í•´ì¤˜!
ì¡°ê±´3 : ìœ ì €ê°€ ë³„ë„ì˜ ë°ì´í„°ë¥¼ ì œê³µí•˜ë©´(<ë°ì´í„°>...</ë°ì´í„°>ë¡œ ì œê³µ), ì œê³µëœ ë°ì´í„°ì—ì„œë§Œ ë‹µë³€ í•´ì¤˜

language:{language}
"""

# Ask user for their OpenAI API key.
openai_api_key = os.getenv("OPENAI_API_KEY")
vector_id = os.getenv("vector_id")

if not openai_api_key:
    st.info("Please add your OpenAI API key to continue.", icon="ğŸ—ï¸")
else:
    client = OpenAI(api_key=openai_api_key)

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "system", "content": response_prompt}]

    # ì–¸ì–´ ë˜ëŠ” ë°ì´í„° ë³€ê²½ ì‹œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
    if st.session_state.messages[0]["content"] != system_prompt:
        st.session_state.messages = [{"role": "system", "content": response_prompt}]

    # Display existing chat messages.
    for message in st.session_state.messages[1:]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Chat input field
    if user_prompt := st.chat_input("Enter your message:"):
        st.session_state.messages.append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        query_parsing = routing(first_prompt, user_prompt, client)
        response = generate_response(query_parsing, client, vector_id, copy.deepcopy(messages))

        
        with st.chat_message("assistant"):
            response = st.markdown(stream)
        st.session_state.messages.append({"role": "assistant", "content": response})

        # Supabase ë¡œê¹… ì‹¤í–‰
        log_to_supabase(prompt, response, st.session_state.messages)
